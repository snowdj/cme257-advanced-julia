{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class 8 - Multithreading in Julia\n",
    "\n",
    "Today we'll talk a bit about Julia's built-in tecniques for taking advantage of multithreading. Note that this notebook makes use of some new features in Julia 1.3.0. If you would like to follow along please install the current release candidate (rc5).\n",
    "\n",
    "* [Julia's Parallel Documentation](https://docs.julialang.org/en/v1/manual/parallel-computing)\n",
    "\n",
    "## Getting Started\n",
    "To get started, launch Julia 1.3.0-rc5 with the command `JULIA_NUM_THREADS=4 [wherever your Julia binary is]` before opening this notebook. On a Mac, after moving the new Julia to the Applications folder the command is `JULIA_NUM_THREADS=4 /Applications/Julia-1.3.app/Contents/Resources/julia/bin/julia`\n",
    "\n",
    "\n",
    "You can test if this worked by running `Threads.nthreads()`-- the output should be 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "Before we get started with multithreading, we'll briefly go over Julia's interface for Tasks. A Task is essentially a fully specified function call that we have put aside for later. We can create a `Task` with `@task`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (runnable) @0x000000011c9e3a90"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f() = println(\"Hello\")\n",
    "function g(x)\n",
    "    sleep(2)\n",
    "    println(x)\n",
    "    return x\n",
    "end\n",
    "v = 1\n",
    "#Examples of tasks\n",
    "task1 = @task f()\n",
    "task2 = @task (global v = g(\"Hello again\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check if a task has been started with `istaskstarted()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "istaskstarted(task1) = false\n",
      "istaskstarted(task2) = false\n"
     ]
    }
   ],
   "source": [
    "@show istaskstarted(task1)\n",
    "@show istaskstarted(task2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can start a task with `schedule()` and check if it is finished with `istaskdone()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Checking if both tasks are started:\n",
      "istaskstarted(task1) = true\n",
      "istaskstarted(task2) = true\n",
      "Which tasks are done after one second?\n",
      "istaskdone(task1) = true\n",
      "istaskdone(task2) = false\n",
      "Hello again\n",
      "Is task2 done after 2 more seconds?\n",
      "istaskdone(task2) = true\n"
     ]
    }
   ],
   "source": [
    "schedule(task2);\n",
    "schedule(task1);\n",
    "sleep(0.1)\n",
    "println(\"Checking if both tasks are started:\")\n",
    "@show istaskstarted(task1)\n",
    "@show istaskstarted(task2);\n",
    "sleep(1)\n",
    "println(\"Which tasks are done after one second?\")\n",
    "@show istaskdone(task1)\n",
    "@show istaskdone(task2)\n",
    "sleep(2)\n",
    "println(\"Is task2 done after 2 more seconds?\")\n",
    "@show istaskdone(task2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to capture the output of a function that we run as a Task, we can alternatively use `fetch()`. Keep in mind that you need to schedule the task before you can fetch it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "v = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task3 = @task(g(1))\n",
    "schedule(task3)\n",
    "v = fetch(task3)\n",
    "@show v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax `@async` conveniently wraps an expression in a Task and schedules it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vec = [0.0, 0.0, 0.0]\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "vec = zeros(3)\n",
    "function h!(v,i)\n",
    "    sleep(4-i)\n",
    "    println(i)\n",
    "    v[i] = i\n",
    "end\n",
    "for i = 1:3\n",
    "    @async h!(vec,i)\n",
    "end\n",
    "@show vec;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand(1:10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that in the above the vector `vec` is showed before its entries are updated: the `@show` and the calls to `h!` are run asynchronously. If we would like to wait for all asynchronous tasks to complete running before continuing down the code, we can wrap the for loop with the `@sync` macro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "2\n",
      "1\n",
      "vec = [1.0, 2.0, 3.0]\n"
     ]
    }
   ],
   "source": [
    "vec = zeros(3)\n",
    "@sync for i = 1:3\n",
    "    @async h!(vec,i)\n",
    "end\n",
    "@show vec;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that Tasks by themselves all run in a single thread (even when called with `@async`). Thus in compute-bound workloads we do not obtain a performance improvement over not using `Tasks`. However, for network and I/O bound programs scheduling jobs to run asynchronously can give a significant improvement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "This exercise should work in Julia 1.2 .\n",
    "\n",
    "* Implement [sleep sort](https://www.geeksforgeeks.org/sleep-sort-king-laziness-sorting-sleeping/) using Tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Any,1}:\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sleepstore!(i,out)\n",
    "    sleep(i)\n",
    "    push!(out,i)\n",
    "end\n",
    "\n",
    "function sleepsort(v)\n",
    "    out = []\n",
    "    @sync for i in v\n",
    "        @async sleepstore!(i,out)\n",
    "    end\n",
    "    return out\n",
    "end\n",
    "\n",
    "sleepsort([2,5,1,3,4])\n",
    "#Note that the array \"out\" is a wrapper around some pointers: array operations are implemented as function calls.\n",
    "#Thus we can push to it without causing race conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multithreading\n",
    "\n",
    "### Example: Monte Carlo Simulations\n",
    "\n",
    "One of the many ways that computers have aided science is through simulation.  Sometimes you may not have a closed-form way to access a quantity of interest, and can obtain a good guess through running many simulations with parameters drawn from a distribution, and looking at the average behavior of your model.  This class of methods is known as [Monte Carlo methods](https://en.wikipedia.org/wiki/Monte_Carlo_method).  \n",
    "\n",
    "One of the benefits of Monte Carlo methods is that they are often trivially parallelizable, since you can run independent experiments on separate processes, and then aggregate the results in a single round of communication at the end.\n",
    "\n",
    "One of the great uses of Monte Carlo methods is [integration](https://en.wikipedia.org/wiki/Monte_Carlo_integration), which becomes increasingly attractive over high-dimensional domains.  The cannonical example is estimating $\\pi$ by integrating a circle on a square domian.\n",
    "\n",
    "The area of a circle with unit radius is $\\pi r^2 = \\pi$.\n",
    "The area of a square on $[-1, 1]^2$ is 4.  If we place the unit circle in this square, the ratio of their areas is $\\pi/4$.  The idea is that we sample uniformly on this square, and then see what portion of the points lie in the circle.  We know that this ratio should be approximately $\\pi/4$, so re multiply the ratio by 4 to obtain our approximation of $\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 64 points took 0.00989389419555664 seconds and achieved error -0.2665926535897931\n",
      "Sampling 128 points took 1.0967254638671875e-5 seconds and achieved error -0.07909265358979312\n",
      "Sampling 256 points took 7.867813110351562e-6 seconds and achieved error -0.07909265358979312\n",
      "Sampling 512 points took 2.8848648071289062e-5 seconds and achieved error 0.06934484641020688\n",
      "Sampling 1024 points took 4.696846008300781e-5 seconds and achieved error -0.016592653589793116\n",
      "Sampling 2048 points took 9.107589721679688e-5 seconds and achieved error -0.010733278589793116\n",
      "Sampling 4096 points took 0.00017714500427246094 seconds and achieved error -0.023428591089793116\n",
      "Sampling 8192 points took 0.00035190582275390625 seconds and achieved error 0.033700315160206884\n",
      "Sampling 16384 points took 0.0007038116455078125 seconds and achieved error 0.015633908910206884\n",
      "Sampling 32768 points took 0.001402139663696289 seconds and achieved error 0.009408322972706884\n",
      "Sampling 65536 points took 0.0028069019317626953 seconds and achieved error -0.003531130152293116\n",
      "Sampling 131072 points took 0.00452113151550293 seconds and achieved error 0.001015988988331884\n",
      "Sampling 262144 points took 0.006721973419189453 seconds and achieved error 0.007684079808644384\n",
      "Sampling 524288 points took 0.011815071105957031 seconds and achieved error -0.003294618921824366\n",
      "Sampling 1048576 points took 0.023138046264648438 seconds and achieved error 0.000508634252003759\n",
      "Sampling 2097152 points took 0.04667496681213379 seconds and achieved error 0.0004418770498553215\n",
      "Sampling 4194304 points took 0.1135258674621582 seconds and achieved error 0.0014718453115740715\n",
      "Sampling 8388608 points took 0.23530292510986328 seconds and achieved error 1.7015141896337127e-5\n",
      "Sampling 16777216 points took 0.49339795112609863 seconds and achieved error -0.0003120024972638191\n",
      "Sampling 33554432 points took 0.9698479175567627 seconds and achieved error 0.0003940741247454582\n",
      "Sampling 67108864 points took 2.0282139778137207 seconds and achieved error 0.00014075438445004806\n",
      "Sampling 134217728 points took 3.336805820465088 seconds and achieved error -0.00014978845650759354\n",
      "Sampling 268435456 points took 6.338637828826904 seconds and achieved error 9.514193003568039e-5\n",
      "Sampling 536870912 points took 12.774533987045288 seconds and achieved error 9.460253171056365e-6\n",
      "Sampling 1073741824 points took 25.11621904373169 seconds and achieved error 5.369062488469467e-5\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip4300\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip4300)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip4301\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip4300)\" d=\"\n",
       "M279.82 1425.62 L2352.76 1425.62 L2352.76 47.2441 L279.82 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip4302\">\n",
       "    <rect x=\"279\" y=\"47\" width=\"2074\" height=\"1379\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip4302)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  664.421,1425.62 664.421,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4302)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1071.84,1425.62 1071.84,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4302)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1479.25,1425.62 1479.25,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4302)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1886.67,1425.62 1886.67,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4302)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2294.09,1425.62 2294.09,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4302)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  279.82,1379.57 2352.76,1379.57 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4302)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  279.82,1087.35 2352.76,1087.35 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4302)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  279.82,795.131 2352.76,795.131 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4302)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  279.82,502.913 2352.76,502.913 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4302)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  279.82,210.695 2352.76,210.695 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  279.82,1425.62 2352.76,1425.62 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  279.82,1425.62 279.82,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  664.421,1425.62 664.421,1404.94 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1071.84,1425.62 1071.84,1404.94 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1479.25,1425.62 1479.25,1404.94 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1886.67,1425.62 1886.67,1404.94 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2294.09,1425.62 2294.09,1404.94 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  279.82,1379.57 310.914,1379.57 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  279.82,1087.35 310.914,1087.35 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  279.82,795.131 310.914,795.131 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  279.82,502.913 310.914,502.913 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4300)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  279.82,210.695 310.914,210.695 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 664.421, 1479.62)\" x=\"664.421\" y=\"1479.62\">10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1071.84, 1479.62)\" x=\"1071.84\" y=\"1479.62\">15</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1479.25, 1479.62)\" x=\"1479.25\" y=\"1479.62\">20</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1886.67, 1479.62)\" x=\"1886.67\" y=\"1479.62\">25</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 2294.09, 1479.62)\" x=\"2294.09\" y=\"1479.62\">30</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 146.839, 1403.29)\" x=\"146.839\" y=\"1403.29\">10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 200.364, 1375.88)\" x=\"200.364\" y=\"1375.88\">-</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 223.203, 1375.88)\" x=\"223.203\" y=\"1375.88\">5 </text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 146.839, 1111.08)\" x=\"146.839\" y=\"1111.08\">10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 200.364, 1083.67)\" x=\"200.364\" y=\"1083.67\">-</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 223.203, 1083.67)\" x=\"223.203\" y=\"1083.67\">4 </text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 146.839, 818.858)\" x=\"146.839\" y=\"818.858\">10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 200.364, 791.448)\" x=\"200.364\" y=\"791.448\">-</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 223.203, 791.448)\" x=\"223.203\" y=\"791.448\">3 </text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 146.839, 526.641)\" x=\"146.839\" y=\"526.641\">10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 200.364, 499.23)\" x=\"200.364\" y=\"499.23\">-</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 223.203, 499.23)\" x=\"223.203\" y=\"499.23\">2 </text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 146.839, 234.423)\" x=\"146.839\" y=\"234.423\">10</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 200.364, 207.012)\" x=\"200.364\" y=\"207.012\">-</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:38px; text-anchor:start;\" transform=\"rotate(0, 223.203, 207.012)\" x=\"223.203\" y=\"207.012\">1 </text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(0, 1316.29, 1559.48)\" x=\"1316.29\" y=\"1559.48\">Log of n_pts</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4300)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(-90, 89.2861, 736.431)\" x=\"89.2861\" y=\"736.431\">Absolute Value Error</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip4302)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  338.488,86.2547 419.971,240.462 501.455,240.462 582.938,257.154 664.421,438.65 745.905,493.932 827.388,394.867 908.871,348.729 990.355,446.203 1071.84,510.653 \n",
       "  1153.32,635.021 1234.8,793.118 1316.29,536.345 1397.77,643.819 1479.25,880.924 1560.74,898.78 1642.22,746.078 1723.7,1312.11 1805.19,942.947 1886.67,913.31 \n",
       "  1968.15,1043.97 2049.64,1036.07 2131.12,1093.67 2212.6,1386.61 2294.09,1166.28 \n",
       "  \"/>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function π_monte_carlo(n_samples::Int64)\n",
    "    n_circle = 0\n",
    "    for i=1:n_samples\n",
    "        x = rand() * 2 - 1\n",
    "        y = rand() * 2 - 1\n",
    "        r2 = x^2 + y^2\n",
    "        if r2 <= 1\n",
    "            n_circle += 1\n",
    "        end\n",
    "    end\n",
    "    return (n_circle / n_samples) * 4\n",
    "end\n",
    "\n",
    "errors = zeros(0)\n",
    "n_pts = 2 .^collect(6:30) # 2^30 ≈ 1 billion\n",
    "for n_samples in n_pts\n",
    "    t1 = time()\n",
    "    val = π_monte_carlo(n_samples) - π\n",
    "    push!(errors, val)\n",
    "    t2 = time()\n",
    "    println(\"Sampling $n_samples points took $(t2-t1) seconds and achieved error $val\")\n",
    "end\n",
    "using Plots\n",
    "plot(collect(6:30),abs.(errors),yscale=:log10,label=\"\",xlabel=\"Log of n_pts\",ylabel=\"Absolute Value Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes us ~25 sec. to estimate $\\pi$ on a billion points. However, this used only one core on the machine.  What if we want to use more?  \n",
    "\n",
    "## Using more than one thread\n",
    "\n",
    "From the way we started Julia, we know that it has access to four threads right now. However, we need to explicitly use them in our code. The `@spawn` macro creates a Task which Julia will automatically assign to a thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (done) @0x000000011c85aad0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base.Threads.@spawn\n",
    "\n",
    "# spawns process that generates a random matrix\n",
    "m = @spawn randn(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 0.0847162  -2.79024   \n",
       " 0.321051   -0.00593942"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns the output from the task\n",
    "fetch(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that Julia will only give us the value of m if we `fetch` it. In the above example our task completed almost immediately. Of course we can also run more intensive computations than this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "awake (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sleep1(x::Int64)\n",
    "    sleep(x)\n",
    "    #pretend that sleeping is hard work\n",
    "    println(\"Sleep printed $x\")\n",
    "    return 1\n",
    "end\n",
    "\n",
    "function awake(x::Int64)\n",
    "    println(\"Awake printed $x\")\n",
    "    return 2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awake printed 5\n",
      "Sleep printed 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = @spawn sleep1(5)\n",
    "out2 = @spawn awake(5)\n",
    "fetch(out) + fetch(out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that when two threads do not interact, they return their outputs asynchronously just as we expect. Thus `sleep1` prints second even though it was called first. However unlike with normal `Tasks` using `@spawn` genuinely allocates jobs to different threads: it can give speedups for compute-boundworkloads\n",
    "\n",
    "Remember that multithreading is only safe if we can ensure that the threads avoid touching the same memory. Thus when controlling the flow of multithreaded code it is sometimes useful to wait for a slow thread to catch up. We can do this by using the `wait` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleep printed 3\n",
      "Sleep printed 5\n",
      "Awake printed 5\n"
     ]
    }
   ],
   "source": [
    "out = @spawn sleep1(5)\n",
    "out2 = @spawn sleep1(3)\n",
    "wait(out)\n",
    "out2 = @spawn awake(5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this type of threading can give real speedups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  16 bytes\n",
       "  allocs estimate:  1\n",
       "  --------------\n",
       "  minimum time:     114.868 ms (0.00% GC)\n",
       "  median time:      135.779 ms (0.00% GC)\n",
       "  mean time:        136.318 ms (0.00% GC)\n",
       "  maximum time:     147.721 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          37\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "a = collect(1:10^8)\n",
    "function add1!(a,first,last)\n",
    "    for i = first:last\n",
    "        a[i] = 1+a[i]\n",
    "    end\n",
    "    return\n",
    "end\n",
    "\n",
    "@benchmark add1!(a,1,10^8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  1.44 KiB\n",
       "  allocs estimate:  18\n",
       "  --------------\n",
       "  minimum time:     83.144 ms (0.00% GC)\n",
       "  median time:      83.838 ms (0.00% GC)\n",
       "  mean time:        85.524 ms (0.00% GC)\n",
       "  maximum time:     97.190 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          59\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = collect(1:10^8)\n",
    "@benchmark begin\n",
    "t1 = @spawn add1!(a,1,5*10^7)\n",
    "t2 = @spawn add1!(a,5*10^7+1,10^8)\n",
    "wait(t1); wait(t2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common use case for multithreading is for [embarassingly parallel](https://en.wikipedia.org/wiki/Embarrassingly_parallel) tasks. As an example, we might want to apply an operation to every element of a vector. We can conveniently do this with `Threads.@threads for`. This macro automatically divides up the range and assigns each chunk to one of the tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 4 on thread 2\n",
      "i = 1 on thread 1\n",
      "i = 7 on thread 3\n",
      "i = 9 on thread 4\n",
      "i = 8 on thread 3\n",
      "i = 10 on thread 4\n",
      "i = 2 on thread 1\n",
      "i = 5 on thread 2\n",
      "i = 3 on thread 1\n",
      "i = 6 on thread 2\n",
      "a = [1, 1, 1, 2, 2, 2, 3, 3, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "a = collect(1:10)\n",
    "Threads.@threads for i = 1:10\n",
    "   println(\"i = $i on thread $(Threads.threadid())\")\n",
    "    a[i] = Threads.threadid()\n",
    "end\n",
    "@show a;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this knowledge in hand, we can write a multithreaded version of our Monte-Carlo calculator for π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6.342593 seconds (37.97 k allocations: 1.937 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.141614407300949"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function π_multithreaded1(n_samples::Int64)\n",
    "    new_n_samples = div(n_samples,Threads.nthreads())\n",
    "    jobs = []\n",
    "    out = zeros(Threads.nthreads())\n",
    "    for i = 1:Threads.nthreads()\n",
    "        push!(jobs,@spawn π_monte_carlo(new_n_samples))\n",
    "    end\n",
    "    for i = 1:Threads.nthreads()\n",
    "        out[i] = fetch(jobs[i])\n",
    "    end\n",
    "    return sum(out)/Threads.nthreads()\n",
    "end\n",
    "@time π_multithreaded1(2^29)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a 2.5x speedup! However, the following (plausible looking) code returns the wrong answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.126383 seconds (875.64 k allocations: 15.173 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0806503295898438"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function π_multithreaded_bad(n_samples::Int64)\n",
    "    n_circle = 0\n",
    "    Threads.@threads for i=1:n_samples\n",
    "        x = rand() * 2 - 1\n",
    "        y = rand() * 2 - 1\n",
    "        r2 = x^2 + y^2\n",
    "        if r2 <= 1\n",
    "            n_circle += 1\n",
    "        end\n",
    "    end\n",
    "    return (n_circle / n_samples) * 4\n",
    "end\n",
    "@time π_multithreaded_bad(2^20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because each thread is trying to update `n_circle`-- the race conditions mean we get the wrong answer. We can fix this by using `Thread.Atomic`s. An atomic is a primitive (numerical) value which Julia will keep track of during multithreaded iteration. If we only do commutative operations to the global `n_circle`, the Atomic will group the operations within a thread and aggregate them at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.890563 seconds (54.51 k allocations: 2.727 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1415563821792603"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function π_multithreaded_fixed(n_samples::Int64)\n",
    "    n_circle = Threads.Atomic{Int}(0)\n",
    "    Threads.@threads for i=1:n_samples\n",
    "        x = rand() * 2 - 1\n",
    "        y = rand() * 2 - 1\n",
    "        r2 = x^2 + y^2\n",
    "        if r2 <= 1\n",
    "            Threads.atomic_add!(n_circle,1)\n",
    "        end\n",
    "    end\n",
    "    return (n_circle.value / n_samples) * 4\n",
    "end\n",
    "@time π_multithreaded_fixed(2^25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation is not much faster than the serial one. Although atomics in Julia enable us to use multiple threads, they are unfortunately very slow. We can speed this up by  manually partitioning the interval and performing the aggregation ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.441603 seconds (63.25 k allocations: 3.108 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1412243843078613"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this should work in Julia 1.2.0\n",
    "function π_multithreaded_better(n_samples::Int64)\n",
    "    results = zeros(Threads.nthreads())\n",
    "    Threads.@threads for tid = 1:Threads.nthreads()\n",
    "        n_circle = 0\n",
    "        len = div(n_samples, Threads.nthreads())\n",
    "        domain = ((tid-1)*len+1):(tid*len)\n",
    "        for i in domain\n",
    "            x = rand() * 2 - 1\n",
    "            y = rand() * 2 - 1\n",
    "            r2 = x^2 + y^2\n",
    "            if r2 <= 1\n",
    "                n_circle += 1\n",
    "            end\n",
    "        end\n",
    "        results[tid] = n_circle\n",
    "    end\n",
    "    return (sum(results) / n_samples) * 4\n",
    "end\n",
    "@time π_multithreaded_better(2^25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "* Can you add the `@simd` macro to the for-loop?  How does this compare with parallelization?  Can you mix parallelization and `@simd`?\n",
    "* Does `@inbounds` have an effect too?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Advanced Multithreaded Algorithms\n",
    "\n",
    "The `Threads.@spawn` interface is extremely versatile and powerful. We can spawn millions of tasks, and so long as we don't care about the order that most computations run in we can reap the benefits of multiple cores while Julia takes care of the rest. Here is an example of a more complicated multithreaded algorithm, taken from [the announcement of the feature](https://julialang.org/blog/2019/07/multithreading)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mergesort! (generic function with 3 methods)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mergesort!(v, lo::Int=1, hi::Int=length(v))\n",
    "    if lo >= hi\n",
    "        return v\n",
    "    end\n",
    "    if hi - lo < 100000\n",
    "        sort!(view(v, lo:hi), alg = MergeSort)\n",
    "        return v\n",
    "    end\n",
    "    mid = (lo+hi)>>>1 \n",
    "    mergesort!(v, lo, mid) \n",
    "    mergesort!(v, mid+1, hi)              \n",
    "    temp = v[lo:mid]            \n",
    "    i, k, j = 1, lo, mid+1            \n",
    "    @inbounds while k < j <= hi\n",
    "        if v[j] < temp[i]\n",
    "            v[k] = v[j]\n",
    "            j += 1\n",
    "        else\n",
    "            v[k] = temp[i]\n",
    "            i += 1\n",
    "        end\n",
    "        k += 1\n",
    "    end\n",
    "    @inbounds while k < j\n",
    "        v[k] = temp[i]\n",
    "        k += 1\n",
    "        i += 1\n",
    "    end\n",
    "\n",
    "    return v\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "psort! (generic function with 3 methods)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function psort!(v, lo::Int=1, hi::Int=length(v))\n",
    "    if lo >= hi                       # 1 or 0 elements; nothing to do\n",
    "        return v\n",
    "    end\n",
    "    if hi - lo < 100000               # below some cutoff, run in serial\n",
    "        sort!(view(v, lo:hi), alg = MergeSort)\n",
    "        return v\n",
    "    end\n",
    "    mid = (lo+hi)>>>1                 # find the midpoint\n",
    "\n",
    "    half = @spawn psort!(v, lo, mid)  # task to sort the lower half; will run\n",
    "    psort!(v, mid+1, hi)              # in parallel with the current call sorting\n",
    "                                      # the upper half\n",
    "    wait(half)                        # wait for the lower half to finish\n",
    "\n",
    "    temp = v[lo:mid]                  # workspace for merging\n",
    "\n",
    "    i, k, j = 1, lo, mid+1            # merge the two sorted sub-arrays\n",
    "    @inbounds while k < j <= hi\n",
    "        if v[j] < temp[i]\n",
    "            v[k] = v[j]\n",
    "            j += 1\n",
    "        else\n",
    "            v[k] = temp[i]\n",
    "            i += 1\n",
    "        end\n",
    "        k += 1\n",
    "    end\n",
    "    @inbounds while k < j\n",
    "        v[k] = temp[i]\n",
    "        k += 1\n",
    "        i += 1\n",
    "    end\n",
    "\n",
    "    return v\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.535161 seconds (770 allocations: 305.224 MiB, 9.73% gc time)\n"
     ]
    }
   ],
   "source": [
    "x = rand(10^7)\n",
    "@time mergesort!(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.488381 seconds (4 allocations: 160 bytes)\n"
     ]
    }
   ],
   "source": [
    "x = rand(10^7)\n",
    "@time sort!(x);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.797033 seconds (1.90 k allocations: 305.315 MiB)\n"
     ]
    }
   ],
   "source": [
    "x = rand(10^7)\n",
    "@time psort!(x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the massive memory overhead (due to needing to pass around references to `Tasks`), our parallel sorting implementation outperformed the standard library one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "* Below is an implementation of the min-plus product, and a naive parallelization `par_minplus`. Is `par_minplus` faster?\n",
    "* Modify `par_minplus` to accomodate any number of threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function minplus(a)\n",
    "    B = zeros(size(a))\n",
    "    n = size(a)[1]\n",
    "    for i = 1:n\n",
    "        for j = 1:n\n",
    "            value = n+1\n",
    "            for k = 1:n\n",
    "                value = min(value,a[i,k] + a[k,j])\n",
    "            end\n",
    "            B[i,j] = value\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return B\n",
    "end\n",
    "\n",
    "function minplus!(a,i_low = 1, i_hi = size(a)[1], B = zeros(size(a)))\n",
    "    n = size(a)[1]\n",
    "    for i = i_low:i_hi\n",
    "        for j = 1:n\n",
    "            value = n+1\n",
    "            for k = 1:n\n",
    "                value = min(value,a[i,k] + a[k,j])\n",
    "            end\n",
    "            B[i,j] = value\n",
    "        end\n",
    "    end\n",
    "    return B\n",
    "end\n",
    "\n",
    "function par_minplus(a,B=zeros(size(a)))\n",
    "    quarter_n = div(size(a)[1],4)\n",
    "    t1 = @spawn minplus!(a,1,quarter_n,B)\n",
    "    t2 = @spawn minplus!(a,quarter_n+1,2*quarter_n,B)\n",
    "    t3 = @spawn minplus!(a,2*quarter_n+1,3*quarter_n,B)\n",
    "    t4 = @spawn minplus!(a,3*quarter_n+1,4*quarter_n,B)\n",
    "    wait(t1); wait(t2); wait(t3); wait(t4)\n",
    "    return B\n",
    "end\n",
    "\n",
    "A = randn(400,400);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locks\n",
    "\n",
    "As mentioned before, we need to be careful to avoid race conditions when writing multithreaded code. Each thread operates on the same space of memory by default, so if we aren't careful one thread might change something out from under another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (done) @0x000000011bcde410"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function slow_sum(x)\n",
    "    sleep(1)\n",
    "    return sum(x)\n",
    "end\n",
    "x = ones(10)\n",
    "@spawn @show slow_sum(x) #should be 10\n",
    "@spawn x[1] = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix this, we can use a `SpinLock()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 1 obtained lock\n",
      "slow_sum(x) = 10.0\n",
      "Thread 1 released lock\n",
      "Thread 1 obtained lock\n",
      "Thread 1 released lock\n",
      "x[1] = 2.0\n"
     ]
    }
   ],
   "source": [
    "x = ones(10)\n",
    "alock = ReentrantLock()\n",
    "@spawn begin\n",
    "lock(alock)\n",
    "println(\"Thread $(Threads.threadid()) obtained lock\")\n",
    "@show slow_sum(x) #should be 10\n",
    "println(\"Thread $(Threads.threadid()) released lock\")\n",
    "unlock(alock)\n",
    "end\n",
    "@spawn begin\n",
    "lock(alock)\n",
    "println(\"Thread $(Threads.threadid()) obtained lock\")\n",
    "sleep(0.1)\n",
    "x[1] = 2\n",
    "println(\"Thread $(Threads.threadid()) released lock\")\n",
    "unlock(alock)\n",
    "end\n",
    "sleep(2)\n",
    "@show x[1];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of locks in Julia that are worth mentioning: `SpinLock`s and `ReentrantLock`s. The main difference between the two is that a `SpinLock` can deadlock itself, while a `ReentrantLock` cannot. In code,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 1 obtained lock\n",
      "Thread 1 obtained lock\n",
      "Thread 1 released lock\n",
      "Thread 1 released lock\n"
     ]
    }
   ],
   "source": [
    "alock = ReentrantLock()\n",
    "begin\n",
    "lock(alock)\n",
    "println(\"Thread $(Threads.threadid()) obtained lock\")\n",
    "lock(alock)\n",
    "println(\"Thread $(Threads.threadid()) obtained lock\")\n",
    "println(\"Thread $(Threads.threadid()) released lock\")\n",
    "unlock(alock)\n",
    "println(\"Thread $(Threads.threadid()) released lock\")\n",
    "unlock(alock)\n",
    "end;\n",
    "#Thread obtained a lock and tried to obtain it again without unlocking  it first. Julia recognized this and \n",
    "#prevented the thread from blocking itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 2 obtained lock\n",
      "Thread 2 released lock\n"
     ]
    }
   ],
   "source": [
    "alock = Threads.SpinLock()\n",
    "@spawn begin\n",
    "lock(alock)\n",
    "println(\"Thread $(Threads.threadid()) obtained lock\")\n",
    "#lock(alock)\n",
    "#println(\"Thread $(Threads.threadid()) obtained lock\")\n",
    "#println(\"Thread $(Threads.threadid()) released lock\")\n",
    "#unlock(alock)\n",
    "println(\"Thread $(Threads.threadid()) released lock\")\n",
    "unlock(alock)\n",
    "end;\n",
    "#When uncommented, this will kill the thread!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check if a thread is holding a lock with `islocked()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "islocked(alock) = true\n",
      "islocked(alock) = false\n"
     ]
    }
   ],
   "source": [
    "alock = ReentrantLock()\n",
    "@spawn begin\n",
    "    lock(alock)\n",
    "    sleep(5)\n",
    "    unlock(alock)\n",
    "end\n",
    "@spawn begin\n",
    "    sleep(3)\n",
    "    @show islocked(alock)\n",
    "    sleep(3)\n",
    "    @show islocked(alock)\n",
    "end; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `trylock()` attempts to take a lock if it is available. Unlike `lock()`, calling `trylock()` means that the thread will not take the lock when it is available: it only cares if the lock is available in the moment. `trylock()` returns `true` if it succeeds in taking the lock and `false` otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = trylock(alock) = false\n",
      "Failed to take lock\n",
      "a = trylock(alock) = true\n",
      "Took the lock\n"
     ]
    }
   ],
   "source": [
    "alock = ReentrantLock()\n",
    "@spawn begin\n",
    "    lock(alock)\n",
    "    sleep(5)\n",
    "    unlock(alock)\n",
    "end\n",
    "@spawn begin\n",
    "    sleep(3)\n",
    "    @show a = trylock(alock)\n",
    "    if a\n",
    "        unlock(alock) #trylock must be followed by unlock, if it succeeds\n",
    "        println(\"Took the lock\")\n",
    "    else\n",
    "        println(\"Failed to take lock\")\n",
    "    end\n",
    "    sleep(3)\n",
    "    @show a = trylock(alock)\n",
    "    if a\n",
    "        unlock(alock) #trylock must be followed by unlock, if it succeeds\n",
    "        println(\"Took the lock\")\n",
    "    else\n",
    "        println(\"Failed to take lock\")\n",
    "    end\n",
    "end; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia also supports very intricate message-passing schemes amongst `Tasks`, such as semaphore signalling and notifications. We only covered the basics here: if you would like to learn more about this check out the [documentation](https://docs.julialang.org/en/v1.4-dev/base/parallel/#Scheduling-1) or come talk to me after class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A couple small optimization tricks for Multithreaded Julia\n",
    "\n",
    "In Julia, there are two primary ways of obtaining thread safety: locks (which we just covered), and **thread-local state**. Locks are useful to ensure thread safety when the threads don't need to interact very often. However, oftentimes we might want to write code that shares memory amongst threads. We can see this in action in the implementation of `psort!` above:\n",
    "\n",
    "```julia\n",
    "function psort!(v, lo::Int=1, hi::Int=length(v))\n",
    "    if lo >= hi                  \n",
    "        return v\n",
    "    end\n",
    "    if hi - lo < 100000               # below some cutoff, run in serial\n",
    "        sort!(view(v, lo:hi), alg = MergeSort)\n",
    "        return v\n",
    "    end\n",
    "    \n",
    "    mid = (lo+hi)>>>1                 # These are the critical lines for us\n",
    "    half = @spawn psort!(v, lo, mid)  # \n",
    "    psort!(v, mid+1, hi)              # \n",
    "    wait(half)                        # \n",
    "    temp = v[lo:mid]                  # \n",
    "\n",
    "    i, k, j = 1, lo, mid+1            \n",
    "    @inbounds while k < j <= hi\n",
    "        if v[j] < temp[i]\n",
    "            v[k] = v[j]\n",
    "            j += 1\n",
    "        else\n",
    "            v[k] = temp[i]\n",
    "            i += 1\n",
    "        end\n",
    "        k += 1\n",
    "    end\n",
    "    @inbounds while k < j\n",
    "        v[k] = temp[i]\n",
    "        k += 1\n",
    "        i += 1\n",
    "    end\n",
    "\n",
    "    return v\n",
    "end\n",
    "\n",
    "```\n",
    "\n",
    "There are two places where we would want to use shared memory in this implementation of Merge Sort. First, we obviously would like our threads to sort the array `v` in place and avoid unnecessary memory allocations. We accomplished thread safety by ensuring that no two `Tasks` ever saw overlapping ranges of the input: this is safe in Julia.\n",
    "\n",
    "Second and less obviously, we would like to reuse the `temp` array during the recursion. Right now, in every level of the recursion a new `temp` array is defined: eventually a thread will have many spurious `temp` arrays that it no longer needs from lower levels of the recursion. However, this is not obvious to do, as these arrays come from different tasks entirely!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get around this issue, we utilize the fact that a `Task` can know which thread it is running in. Thus, the Task can write to a *thread's* `temp` array instead of creating a new one from scratch. This reusing of space is known as thread-local state: local variables during a recursion are reused within a thread."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modifications we need are:\n",
    "\n",
    "* Change the function signature to \n",
    "```julia\n",
    "function psort!(v, lo::Int=1, hi::Int=length(v), temps=[similar(v, 0) for i = 1:Threads.nthreads()])\n",
    "```\n",
    "* Change the recursive calls to `psort!` to use the temporary ranges;\n",
    "``` julia\n",
    "half = @spawn psort!(v, lo, mid, temps)\n",
    "psort!(v, mid+1, hi, temps)\n",
    "```\n",
    "* Modify the allocation of the `temp` array to stay within the ranges we defined on each thread\n",
    "``` julia\n",
    "temp = temps[Threads.threadid()]\n",
    "length(temp) < mid-lo+1 && resize!(temp, mid-lo+1)\n",
    "copyto!(temp, 1, v, lo, mid-lo+1)\n",
    "```\n",
    "\n",
    "Plugging these in, we obtain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "psort2! (generic function with 4 methods)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function psort2!(v, lo::Int=1, hi::Int=length(v), temps=[similar(v, 0) for i = 1:Threads.nthreads()])\n",
    "    if lo >= hi                  \n",
    "        return v\n",
    "    end\n",
    "    if hi - lo < 100000               # below some cutoff, run in serial\n",
    "        sort!(view(v, lo:hi), alg = MergeSort)\n",
    "        return v\n",
    "    end\n",
    "    \n",
    "    mid = (lo+hi)>>>1                 \n",
    "    half = @spawn psort2!(v, lo, mid, temps)\n",
    "    psort2!(v, mid+1, hi, temps)\n",
    "    wait(half)                         \n",
    "    temp = temps[Threads.threadid()]\n",
    "    length(temp) < mid-lo+1 && resize!(temp, mid-lo+1) #fancy way to implement an if-else statement\n",
    "    copyto!(temp, 1, v, lo, mid-lo+1)                \n",
    "\n",
    "    i, k, j = 1, lo, mid+1            \n",
    "    @inbounds while k < j <= hi\n",
    "        if v[j] < temp[i]\n",
    "            v[k] = v[j]\n",
    "            j += 1\n",
    "        else\n",
    "            v[k] = temp[i]\n",
    "            i += 1\n",
    "        end\n",
    "        k += 1\n",
    "    end\n",
    "    @inbounds while k < j\n",
    "        v[k] = temp[i]\n",
    "        k += 1\n",
    "        i += 1\n",
    "    end\n",
    "\n",
    "    return v\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.348519 seconds (1.68 k allocations: 77.019 MiB)\n"
     ]
    }
   ],
   "source": [
    "a = rand(10^7)\n",
    "@time psort2!(a);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an enormous amount of worked planned on extending the features covered here. The future is looking bright for Julia.\n",
    "\n",
    "# Thanks for a great quarter!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.3.0-rc5",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
